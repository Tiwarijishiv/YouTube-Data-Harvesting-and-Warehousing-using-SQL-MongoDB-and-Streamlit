{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pymongo\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import re\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.6.2)\n",
      "Requirement already satisfied: google-api-python-client in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.108.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pymongo) (2.4.2)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-python-client) (2.23.4)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-python-client) (0.1.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-python-client) (2.14.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.61.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.21.12)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.6.2)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pymongo) (2.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API ID connection\n",
    "def api_connect():\n",
    "    Api_Key = \"AIzaSyDcGJkEcPAxMXVYvUm0ByGYz102o9KhLVw\"\n",
    "    Api_service_name = \"youtube\"\n",
    "    Api_version = \"v3\"\n",
    "    youtube = build(Api_service_name,Api_version,developerKey = Api_Key)\n",
    "    return youtube\n",
    "youtube = api_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total five channel details are uploading.\n",
    "#1-channel_id-\"UCydCfd5ACPMqjZg25LI5RFA\"\n",
    "#Channel_name-\"Coding with Chirag\"\n",
    "#2-ID-UCAJcxMaiGu-cjzklR-63ojw\n",
    "#3-ID-UC_NGoezF2f_GK3wU2CaquHg\n",
    "#4-ID-UCSX5Gk1UvlYWYyjeVZFnp-w\n",
    "#5-ID-UCx6ZLQae1a6-elAgh_f-sXQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_info(channel_id):\n",
    "    request = youtube.channels().list(\n",
    "                part = \"snippet,ContentDetails,statistics\",\n",
    "                id = channel_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    for i in response['items']:\n",
    "            data = dict(Channel_Name = i['snippet']['title'],\n",
    "                        Channel_Id = i['id'],\n",
    "                        Subscribers = i['statistics']['subscriberCount'],\n",
    "                        Views = i['statistics']['viewCount'],\n",
    "                        Total_videos = i['statistics']['videoCount'],\n",
    "                        Channel_Description = i['snippet']['description'],\n",
    "                        Playlist_Id = i['contentDetails']['relatedPlaylists']['uploads'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Channel_Name': 'Coding with Chirag',\n",
       " 'Channel_Id': 'UCydCfd5ACPMqjZg25LI5RFA',\n",
       " 'Subscribers': '85',\n",
       " 'Views': '496',\n",
       " 'Total_videos': '14',\n",
       " 'Channel_Description': \"Welcome to Coding with Chirag, your ultimate destination for learning diverse topics together! On this channel, we delve into a copious range of educational content, from coding tutorials to insightful discussions. By subscribing to this channel, you will receive timely notifications whenever I upload a new video, ensuring that you never miss out on the opportunity to expand your knowledge. Join our dynamic community today and let's embark on this enlightening journey together. Don't forget to hit that subscribe button!\",\n",
       " 'Playlist_Id': 'UUydCfd5ACPMqjZg25LI5RFA'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_channel_info('UCydCfd5ACPMqjZg25LI5RFA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Video ID\n",
    "\n",
    "def get_video_ids(channel_id):\n",
    "    video_ids = []\n",
    "    response = youtube.channels().list(id = channel_id,\n",
    "                                      part = 'contentDetails').execute()\n",
    "    Playlist_Id = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        response1 = youtube.playlistItems().list(\n",
    "                                                part = 'snippet',\n",
    "                                                playlistId = Playlist_Id,\n",
    "                                                maxResults = 50,\n",
    "                                                pageToken = next_page_token).execute()\n",
    "        for i in range(len(response1['items'])):\n",
    "            video_ids.append(response1['items'][i]['snippet']['resourceId']['videoId'])\n",
    "        next_page_token = response1.get('nextPageToken')\n",
    "\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    return video_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YozLzzVofD0',\n",
       " 'RizScP1Vcs8',\n",
       " 'SfDh5qvRdFo',\n",
       " '9Fwctmjx9-s',\n",
       " 'iBaaGyJHZlk',\n",
       " 'peV8R8ZtBWQ',\n",
       " 'Rsa637rNbok',\n",
       " 'CXcXNeO_T00',\n",
       " '-7JEuDzXlbs',\n",
       " 'O2BX6DKYalQ',\n",
       " 'hUI_BfPrsB0',\n",
       " 'Z2JvsciRoyY',\n",
       " '7MPfmNnIvRs',\n",
       " 'Z76IOXm51ig',\n",
       " 'uq4LKoO-c18']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_video_ids('UCydCfd5ACPMqjZg25LI5RFA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Video Infromation\n",
    "\n",
    "def get_video_info(video_ids):\n",
    "    video_data = []\n",
    "    for video_id in video_ids:\n",
    "        request = youtube.videos().list(\n",
    "                        part = \"snippet,contentDetails,statistics\",\n",
    "                        id = video_id)\n",
    "        response = request.execute()\n",
    "        for item in response['items']:\n",
    "            data = dict(Channel_Name = item['snippet']['channelTitle'],\n",
    "                        Channel_Id = item['snippet']['channelId'],\n",
    "                        Video_Id = item['id'],\n",
    "                        Title = item['snippet']['title'],\n",
    "                        Thumbnails = item['snippet']['thumbnails']['default']['url'],\n",
    "                        Description = item['snippet'].get('description'),\n",
    "                        Publish_At = item['snippet']['publishedAt'],\n",
    "                        Duration = item['contentDetails']['duration'],\n",
    "                        Views = item['statistics'].get('viewCount'),\n",
    "                        Comments = item['statistics'].get('commentCount'),\n",
    "                        Favorite = item['statistics']['favoriteCount'],\n",
    "                        Definition = item['contentDetails']['definition'],\n",
    "                        Caption = item['contentDetails']['caption'],\n",
    "                        Likes = item['statistics'].get('likeCount'),\n",
    "                        Tags = item['snippet'].get('tags')) \n",
    "            video_data.append(data)\n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Channel_Name': 'Coding with Chirag',\n",
       "  'Channel_Id': 'UCydCfd5ACPMqjZg25LI5RFA',\n",
       "  'Video_Id': 'uq4LKoO-c18',\n",
       "  'Title': 'Building Game - C1 - Setting p5 editor',\n",
       "  'Thumbnails': 'https://i.ytimg.com/vi/uq4LKoO-c18/default.jpg',\n",
       "  'Description': '',\n",
       "  'Publish_At': '2020-11-01T06:45:09Z',\n",
       "  'Duration': 'PT2M59S',\n",
       "  'Views': '52',\n",
       "  'Comments': '2',\n",
       "  'Favorite': '0',\n",
       "  'Definition': 'hd',\n",
       "  'Caption': 'false',\n",
       "  'Likes': '14',\n",
       "  'Tags': None},\n",
       " {'Channel_Name': 'Coding with Chirag',\n",
       "  'Channel_Id': 'UCydCfd5ACPMqjZg25LI5RFA',\n",
       "  'Video_Id': 'YozLzzVofD0',\n",
       "  'Title': 'Learn about databases💻🔍 #Database #DataCollection #TechCompanies #Facebook #Google #Microsoft',\n",
       "  'Thumbnails': 'https://i.ytimg.com/vi/YozLzzVofD0/default.jpg',\n",
       "  'Description': '',\n",
       "  'Publish_At': '2024-01-30T14:51:53Z',\n",
       "  'Duration': 'PT30S',\n",
       "  'Views': '8',\n",
       "  'Comments': '0',\n",
       "  'Favorite': '0',\n",
       "  'Definition': 'hd',\n",
       "  'Caption': 'false',\n",
       "  'Likes': '3',\n",
       "  'Tags': None}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_video_info(['uq4LKoO-c18','YozLzzVofD0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Comment Information\n",
    "\n",
    "def get_comment_info(video_ids):\n",
    "    Comment_data = []\n",
    "    try:\n",
    "        for video_id in video_ids:\n",
    "            request = youtube.commentThreads().list(\n",
    "                            part = 'snippet',\n",
    "                            videoId = video_id,\n",
    "                            maxResults = 100\n",
    "            )\n",
    "            response = request.execute()\n",
    "            for item in response['items']:\n",
    "                data = dict(Comment_Id = item['snippet']['topLevelComment']['id'],\n",
    "                            Video_Id = item['snippet']['topLevelComment']['snippet']['videoId'],\n",
    "                            Comment_Text = item['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
    "                            Comment_Author = item['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
    "                            comment_Published_Date = item['snippet']['topLevelComment']['snippet']['publishedAt'])\n",
    "                Comment_data.append(data)\n",
    "    except:\n",
    "        pass\n",
    "    return Comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_info(channel_id):\n",
    "    \n",
    "    next_page_token = None\n",
    "\n",
    "    All_Data = []\n",
    "\n",
    "    while True:\n",
    "        request = youtube.playlists().list(\n",
    "                        part = 'snippet,contentDetails',\n",
    "                        channelId = channel_id,\n",
    "                        maxResults = 50,\n",
    "                        pageToken = next_page_token)\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            data = dict(Playlist_Id = item['id'],\n",
    "                        Channel_Id = item['snippet']['channelId'],\n",
    "                        Playlist_Name = item['snippet']['title'],\n",
    "                        Channel_Name = item['snippet']['channelTitle'],\n",
    "                        Published_At = item['snippet']['publishedAt'],\n",
    "                        Video_count = item['contentDetails']['itemCount'])\n",
    "            All_Data.append(data)\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if next_page_token is None:\n",
    "                break\n",
    "    return All_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload to Mongodb\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"youtube_data\"]\n",
    "\n",
    "def channel_details(channel_id):\n",
    "    ch_details = get_channel_info(channel_id)\n",
    "    pl_details = get_playlist_info(channel_id)\n",
    "    vi_ids = get_video_ids(channel_id)\n",
    "    vi_details = get_video_info(vi_ids)\n",
    "    com_details = get_comment_info(vi_ids)\n",
    "    \n",
    "    coll1 = db[\"channel_details\"]\n",
    "    coll1.insert_one({\"Channel_information\":ch_details,\"Playlist_information\":pl_details,\"Video_information\":vi_details,\"Comment_information\":com_details})\n",
    "    \n",
    "    return \"upload completed successfully\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total five channel details are uploading.\n",
    "#1-channel_id-\"UCydCfd5ACPMqjZg25LI5RFA\"\n",
    "#Channel_name-\"Coding with Chirag\"\n",
    "#2-ID-UCAJcxMaiGu-cjzklR-63ojw\n",
    "#3-ID-UC_NGoezF2f_GK3wU2CaquHg\n",
    "#4-ID-UCSX5Gk1UvlYWYyjeVZFnp-w\n",
    "#5-ID-UCx6ZLQae1a6-elAgh_f-sXQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'upload completed successfully'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_details('UCx6ZLQae1a6-elAgh_f-sXQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channels_tabel():\n",
    "\n",
    "    config = {'host' : 'localhost',\n",
    "              'user' : 'root',\n",
    "              'password' : 'up78aq3670',\n",
    "              'database' : 'youtube_data'}\n",
    "\n",
    "    conn = mysql.connector.connect(**config)\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Insert Many values in the table\n",
    "\n",
    "    drop_query = '''drop table IF EXISTS channels'''\n",
    "    cursor.execute(drop_query)\n",
    "    conn.commit()\n",
    "\n",
    "    create_table_sql = '''\n",
    "    CREATE TABLE IF NOT EXISTS channels (\n",
    "        Channel_Name VARCHAR(255),\n",
    "        Channel_Id VARCHAR(255) PRIMARY KEY,\n",
    "        Subscribers BIGINT,\n",
    "        Views BIGINT,\n",
    "        Total_videos INT,\n",
    "        Channel_Description TEXT,\n",
    "        Playlist_Id VARCHAR(255)\n",
    "    );\n",
    "    '''\n",
    "\n",
    "    cursor.execute(create_table_sql)\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "    ch_list = []\n",
    "    db = client[\"youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"Channel_information\":1}):\n",
    "        ch_list.append(ch_data[\"Channel_information\"])\n",
    "    df = pd.DataFrame(ch_list)\n",
    "\n",
    "    # Insert values in the MySQL table\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        insert_qurey = '''INSERT INTO channels (Channel_Name,\n",
    "                                                Channel_Id,\n",
    "                                                Subscribers,\n",
    "                                                Views,\n",
    "                                                Total_videos,\n",
    "                                                Channel_Description,\n",
    "                                                Playlist_Id)\n",
    "\n",
    "                                                VALUES (%s, %s, %s, %s, %s, %s, %s)'''\n",
    "        values = (row['Channel_Name'],\n",
    "                  row['Channel_Id'],\n",
    "                  row['Subscribers'],\n",
    "                  row['Views'],\n",
    "                  row['Total_videos'],\n",
    "                  row['Channel_Description'],\n",
    "                  row['Playlist_Id'])\n",
    "\n",
    "        try:\n",
    "            cursor.execute(insert_qurey, values)\n",
    "            conn.commit()\n",
    "\n",
    "        except:\n",
    "            print(\"Channel values are already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_tabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table creation for playlists\n",
    "\n",
    "def playlist_table():\n",
    "    \n",
    "    config = {'host' : 'localhost',\n",
    "                  'user' : 'root',\n",
    "                  'password' : 'up78aq3670',\n",
    "                  'database' : 'youtube_data'}\n",
    "\n",
    "    conn = mysql.connector.connect(**config)\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Insert Many values in the table\n",
    "\n",
    "    drop_query = '''drop table IF EXISTS playlists'''\n",
    "    cursor.execute(drop_query)\n",
    "    conn.commit()\n",
    "\n",
    "    create_table_sql = '''\n",
    "        CREATE TABLE IF NOT EXISTS playlists (\n",
    "            Playlist_Id VARCHAR(255) PRIMARY KEY,\n",
    "            Playlist_Name VARCHAR(255),\n",
    "            Channel_Id VARCHAR(255),\n",
    "            Channel_Name VARCHAR(255),\n",
    "            Published_At TIMESTAMP,\n",
    "            Video_count INT\n",
    "    );\n",
    "    '''\n",
    "\n",
    "    cursor.execute(create_table_sql)\n",
    "\n",
    "    conn.commit()\n",
    "    \n",
    "    pl_list = []\n",
    "    db = client[\"youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for pl_data in coll1.find({},{\"_id\":0,\"Playlist_information\":1}):\n",
    "        for i in range(len(pl_data[\"Playlist_information\"])):\n",
    "            pl_list.append(pl_data[\"Playlist_information\"][i])\n",
    "\n",
    "    df1 = pd.DataFrame(pl_list)\n",
    "    \n",
    "# Table connecting to MSQL :\n",
    "\n",
    "    for index,row in df1.iterrows():\n",
    "        insert_qurey = '''INSERT INTO playlists (Playlist_Id,\n",
    "                                                Playlist_Name,\n",
    "                                                Channel_Id,\n",
    "                                                Channel_Name,\n",
    "                                                Published_At,\n",
    "                                                Video_count)\n",
    "                                                \n",
    "                                                VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "        published_at_mysql_format = datetime.strptime(row['Published_At'], '%Y-%m-%dT%H:%M:%SZ').strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        values = (row['Playlist_Id'],\n",
    "                  row['Playlist_Name'],\n",
    "                  row['Channel_Id'],\n",
    "                  row['Channel_Name'],\n",
    "                  published_at_mysql_format,\n",
    "                  row['Video_count'])\n",
    "                  \n",
    "     \n",
    "        cursor.execute(insert_qurey, values)\n",
    "        conn.commit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_duration(duration):\n",
    "            regex = r'PT(\\d+H)?(\\d+M)?(\\d+S)?'\n",
    "            match = re.match(regex, duration)\n",
    "            if not match:\n",
    "                return '00:00:00'\n",
    "            hours, minutes, seconds = match.groups()\n",
    "            hours = int(hours[:-1]) if hours else 0\n",
    "            minutes = int(minutes[:-1]) if minutes else 0\n",
    "            seconds = int(seconds[:-1]) if seconds else 0\n",
    "            total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "            time_data ='{:02d}:{:02d}:{:02d}'.format(int(total_seconds / 3600), int((total_seconds % 3600) / 60), int(total_seconds % 60))\n",
    "            format_data = \"%H:%M:%S\"\n",
    "            date = datetime.strptime(time_data, format_data)    \n",
    "            time = date.time()\n",
    "            return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table creation for videos in MySQL\n",
    "\n",
    "def videos_table():\n",
    "\n",
    "    config = {'host' : 'localhost',\n",
    "                  'user' : 'root',\n",
    "                  'password' : 'up78aq3670',\n",
    "                  'database' : 'youtube_data'}\n",
    "\n",
    "    conn = mysql.connector.connect(**config)\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Insert Many values in the table\n",
    "\n",
    "    drop_query = '''drop table IF EXISTS videos'''\n",
    "    cursor.execute(drop_query)\n",
    "    conn.commit()\n",
    "\n",
    "    create_table_sql = '''\n",
    "        CREATE TABLE IF NOT EXISTS videos (\n",
    "                            Channel_Name VARCHAR(255),\n",
    "                            Channel_Id VARCHAR(255),\n",
    "                            Video_Id VARCHAR(255) PRIMARY KEY,\n",
    "                            Title VARCHAR(255),\n",
    "                            Thumbnails VARCHAR(255),\n",
    "                            Description TEXT,\n",
    "                            Publish_At TIMESTAMP,\n",
    "                            Duration VARCHAR(255),\n",
    "                            Views BIGINT,\n",
    "                            Comments INT,\n",
    "                            Favorite INT,\n",
    "                            Likes BIGINT,\n",
    "                            Definition VARCHAR(255),\n",
    "                            Caption VARCHAR(255),                        \n",
    "                            Tags TEXT \n",
    "    );\n",
    "    '''\n",
    "\n",
    "    cursor.execute(create_table_sql)\n",
    "\n",
    "    conn.commit()\n",
    "    \n",
    "    \n",
    "    vi_list = []\n",
    "    db = client[\"youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for vi_data in coll1.find({},{\"_id\":0,\"Video_information\":1}):\n",
    "        for i in range(len(vi_data[\"Video_information\"])):\n",
    "            vi_list.append(vi_data[\"Video_information\"][i])\n",
    "\n",
    "    df2 = pd.DataFrame(vi_list)\n",
    "    \n",
    "    \n",
    "    # Table connecting to MSQL :\n",
    "\n",
    "    for index,row in df2.iterrows():\n",
    "            insert_qurey = '''INSERT INTO videos (Channel_Name,\n",
    "                                                    Channel_Id,\n",
    "                                                    Video_Id,\n",
    "                                                    Title,\n",
    "                                                    Thumbnails,\n",
    "                                                    Description,\n",
    "                                                    Publish_At,\n",
    "                                                    Duration,\n",
    "                                                    Views,\n",
    "                                                    Comments,\n",
    "                                                    Favorite,\n",
    "                                                    Likes,\n",
    "                                                    Definition,\n",
    "                                                    Caption,                        \n",
    "                                                    Tags)\n",
    "\n",
    "                                                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "            published_at_mysql_format = datetime.strptime(row['Publish_At'], '%Y-%m-%dT%H:%M:%SZ').strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            Duration_formate = convert_duration(row['Duration'])\n",
    "\n",
    "            tags_str = ', '.join(row['Tags']) if isinstance(row['Tags'], list) else row['Tags']\n",
    "\n",
    "\n",
    "            values = (row['Channel_Name'],\n",
    "                      row['Channel_Id'],\n",
    "                      row['Video_Id'],\n",
    "                      row['Title'],\n",
    "                      row['Thumbnails'],\n",
    "                      row['Description'],                  \n",
    "                      published_at_mysql_format,\n",
    "                      Duration_formate,\n",
    "                      row['Views'],\n",
    "                      row['Comments'],\n",
    "                      row['Favorite'],\n",
    "                      row['Likes'],\n",
    "                      row['Definition'],\n",
    "                      row['Caption'],\n",
    "                      tags_str)\n",
    "\n",
    "\n",
    "            cursor.execute(insert_qurey, values)\n",
    "            conn.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table creation for comments in MySQL\n",
    "\n",
    "def comments_table():\n",
    "\n",
    "    config = {'host' : 'localhost',\n",
    "              'user' : 'root',\n",
    "              'password' : 'up78aq3670',\n",
    "              'database' : 'youtube_data'}\n",
    "\n",
    "    conn = mysql.connector.connect(**config)\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Insert Many values in the table\n",
    "\n",
    "    drop_query = '''drop table IF EXISTS comments'''\n",
    "    cursor.execute(drop_query)\n",
    "    conn.commit()\n",
    "\n",
    "    create_table_sql = '''\n",
    "        CREATE TABLE IF NOT EXISTS comments (Comment_Id VARCHAR(255) PRIMARY KEY,\n",
    "                                             Video_Id VARCHAR(255),\n",
    "                                             Comment_Text TEXT,\n",
    "                                             Comment_Author VARCHAR(255),\n",
    "                                             comment_Published_Date TIMESTAMP\n",
    "\n",
    "    );\n",
    "    '''\n",
    "\n",
    "    cursor.execute(create_table_sql)\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    com_list = []\n",
    "    db = client[\"youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for com_data in coll1.find({},{\"_id\":0,\"Comment_information\":1}):\n",
    "        for i in range(len(com_data[\"Comment_information\"])):\n",
    "            com_list.append(com_data[\"Comment_information\"][i])\n",
    "    df3 = pd.DataFrame(com_list)\n",
    "\n",
    "# Table connecting to MSQL :\n",
    "\n",
    "    for index,row in df3.iterrows():\n",
    "            insert_qurey = '''INSERT INTO comments (Comment_Id,\n",
    "                                                     Video_Id,\n",
    "                                                     Comment_Text,\n",
    "                                                     Comment_Author,\n",
    "                                                     comment_Published_Date)\n",
    "\n",
    "                                                    VALUES (%s, %s, %s, %s, %s)'''\n",
    "            published_at_mysql_format = datetime.strptime(row['comment_Published_Date'], '%Y-%m-%dT%H:%M:%SZ').strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            values = (row['Comment_Id'],\n",
    "                      row['Video_Id'],\n",
    "                      row['Comment_Text'],\n",
    "                      row['Comment_Author'],                  \n",
    "                      published_at_mysql_format\n",
    "                      )\n",
    "\n",
    "\n",
    "            cursor.execute(insert_qurey, values)\n",
    "            conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables():\n",
    "    channels_tabel()\n",
    "    playlist_table()\n",
    "    videos_table()\n",
    "    comments_table()\n",
    "    \n",
    "    return \"Tables created successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tables created successfully'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channels_table():\n",
    "    ch_list = []\n",
    "    db = client[\"youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"Channel_information\":1}):\n",
    "        ch_list.append(ch_data[\"Channel_information\"])\n",
    "    df = st.dataframe(ch_list)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_playlists_table():\n",
    "    pl_list = []\n",
    "    db = client[\"youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for pl_data in coll1.find({},{\"_id\":0,\"Playlist_information\":1}):\n",
    "        for i in range(len(pl_data[\"Playlist_information\"])):\n",
    "            pl_list.append(pl_data[\"Playlist_information\"][i])\n",
    "\n",
    "    df1 = st.dataframe(pl_list)\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_videos_table():\n",
    "    vi_list = []\n",
    "    db = client[\"youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for vi_data in coll1.find({},{\"_id\":0,\"Video_information\":1}):\n",
    "        for i in range(len(vi_data[\"Video_information\"])):\n",
    "            vi_list.append(vi_data[\"Video_information\"][i])\n",
    "\n",
    "    df2 = st.dataframe(vi_list)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comments_table():\n",
    "    com_list = []\n",
    "    db = client[\"youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for com_data in coll1.find({},{\"_id\":0,\"Comment_information\":1}):\n",
    "        for i in range(len(com_data[\"Comment_information\"])):\n",
    "            com_list.append(com_data[\"Comment_information\"][i])\n",
    "    df3 = st.dataframe(com_list)\n",
    "    \n",
    "    return df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit Part\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"Skill Take Away\")\n",
    "    st.caption(\"Python Scripting\")\n",
    "    st.caption(\"Data Collection\")\n",
    "    st.caption(\"MongoDB\")\n",
    "    st.caption(\"API Integration\")\n",
    "    st.caption(\"Data Management using MongoDB and SQL\")\n",
    "\n",
    "st.title(\":red[YOU TUBE DATA HARVESTING AND WAREHOUSING]\")   \n",
    "channel_id = st.text_input(\"Enter the Channel ID\")\n",
    "\n",
    "if st.button(\"Collect and Store Data\"):\n",
    "    ch_ids = []\n",
    "    db = client[\"youtube_data\"]\n",
    "    coll1 = db[\"channel_details\"]\n",
    "    for ch_data in coll1.find({},{\"_id\":0,\"Channel_information\":1}):\n",
    "        ch_ids.append(ch_data[\"Channel_information\"][\"Channel_Id\"])\n",
    "        \n",
    "    if channel_id in ch_ids:\n",
    "        st.success(\"Channels Details of given Channel ID already Exists\")\n",
    "    else:\n",
    "        insert = channel_details(channel_id)\n",
    "        st.success(insert)\n",
    "        \n",
    "if st.button(\"Migrate to SQL\"):\n",
    "    Table = tables()\n",
    "    st.success(Table)\n",
    "    st.balloons()\n",
    "    \n",
    "show_table = st.radio(\"SELECT THE TABLE FOR VIEW [MONGODB VALUES IN TABLE FORMATE]\",(\"CHANNALS\",\"PLAYLISTS\",\"VIDEOS\",\"COMMENTS\"))\n",
    "\n",
    "if show_table == \"CHANNALS\":\n",
    "    show_channels_table()\n",
    "    \n",
    "elif show_table == \"PLAYLISTS\":\n",
    "    show_playlists_table()\n",
    "    \n",
    "elif show_table == \"VIDEOS\":\n",
    "    show_videos_table()\n",
    "    \n",
    "elif show_table == \"COMMENTS\":\n",
    "    show_comments_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Channel Analysis\n",
    "# Database connection parameters\n",
    "config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': 'up78aq3670',\n",
    "    'database': 'youtube_data'\n",
    "}\n",
    "\n",
    "st.header(':orange[Channel Name Analysis zone]')\n",
    "st.write('''(Note:- This zone **Analysis of a collection of channel name** shows your Channel Names and gives in table format.)''')\n",
    "Check_channel = st.checkbox('**Check available channel name for analysis**')\n",
    "\n",
    "if Check_channel:\n",
    "    conn = mysql.connector.connect(**config)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query = \"SELECT Channel_Name FROM channels;\"\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch results and create a DataFrame\n",
    "    results = cursor.fetchall()\n",
    "    conn.commit()\n",
    "    df_at_sql = pd.DataFrame(results, columns=['Available channel data']).reset_index(drop=True)\n",
    "    df_at_sql.index += 1  # Reset index to start from 1 instead of 0\n",
    "\n",
    "    # Show dataframe\n",
    "    st.dataframe(df_at_sql)\n",
    "\n",
    "    # Close cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Connection\n",
    "\n",
    "config = {'host' : 'localhost',\n",
    "          'user' : 'root',\n",
    "          'password' : 'up78aq3670',\n",
    "          'database' : 'youtube_data'}\n",
    "\n",
    "conn = mysql.connector.connect(**config)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "st.markdown('<h1 style=\"color: #ff33db;\">SQL Query</h1>', unsafe_allow_html=True)\n",
    "sql_query = st.checkbox('**Check SQL Query**')\n",
    "if sql_query:\n",
    "    questions = st.selectbox(\"Select Your Questions\",(\"01. The Names of All the Videos and their corresponding Channels\",\n",
    "                                                    \"02. Channels have the most number of Videos\",\n",
    "                                                    \"03. The Top 10 most viewed Videos and their respective Channels\",\n",
    "                                                    \"04. Comments were made on each Video, and their corresponding Video Names\",\n",
    "                                                    \"05. Videos have the highest number of Likes, and their corresponding Channel Names\",\n",
    "                                                    \"06. The Total number of Likes for each Video, and their corresponding Video Names\",\n",
    "                                                    \"07. The Total number of Views for each Channel, and their corresponding Channel Names\",\n",
    "                                                    \"08. The Names of All the Channels that have Published Videos in the Year 2022\",\n",
    "                                                    \"09. The Average Duration of All Videos in each Channel, and corresponding Channel Names\",\n",
    "                                                    \"10. Videos have the highest number of Comments, and their corresponding Channel Names\"))\n",
    "\n",
    "    if questions == \"01. The Names of All the Videos and their corresponding Channels\":\n",
    "        query1 = '''SELECT Title as videos, Channel_Name as ChannelName FROM videos'''\n",
    "        cursor.execute(query1)\n",
    "        t1 = cursor.fetchall()  # Fetch all results\n",
    "        conn.commit()\n",
    "\n",
    "        df = pd.DataFrame(t1, columns=[\"VideoTitle\", \"ChannelName\"])\n",
    "        st.write(df)\n",
    "        \n",
    "    elif questions == \"02. Channels have the most number of Videos\":\n",
    "        query2 = '''SELECT Channel_Name as ChannelName, Total_videos as No_Of_Videos FROM channels\n",
    "                    ORDER BY Total_videos DESC'''\n",
    "        cursor.execute(query2)\n",
    "        t2 = cursor.fetchall()  # Fetch all results\n",
    "        conn.commit()\n",
    "\n",
    "        df2 = pd.DataFrame(t2, columns=[\"ChannelName\",\"No_Of_Videos\"])\n",
    "        st.write(df2)\n",
    "        st.write(\"### :green[Number of videos in each channel :]\")\n",
    "        # Create a Plotly Express bar chart\n",
    "        fig = px.bar(df2,\n",
    "                    x=\"ChannelName\",\n",
    "                    y=\"No_Of_Videos\",\n",
    "                    orientation='v',\n",
    "                    color=\"ChannelName\"\n",
    "                    )\n",
    "\n",
    "        # Display the Plotly chart using Streamlit\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "    elif questions == \"03. The Top 10 most viewed Videos and their respective Channels\":\n",
    "        query3 = '''SELECT Views as views,Channel_Name as ChannelName, Title as VideoTitle FROM videos\n",
    "                    WHERE Views IS NOT NULL ORDER BY Views DESC LIMIT 10'''\n",
    "        cursor.execute(query3)\n",
    "        t3 = cursor.fetchall()  # Fetch all results\n",
    "        conn.commit()\n",
    "\n",
    "        df3 = pd.DataFrame(t3, columns=[\"Views\",\"ChannelName\",\"VideoTitle\"])\n",
    "        st.write(df3)\n",
    "        st.write(\"### :green[Top 10 most viewed videos :]\")\n",
    "        # Create a Plotly Express bar chart\n",
    "        fig = px.bar(df3,\n",
    "                    x=\"Views\",\n",
    "                    y=\"ChannelName\",\n",
    "                    orientation='h',\n",
    "                    color=\"VideoTitle\"\n",
    "                    )\n",
    "\n",
    "        # Display the Plotly chart using Streamlit\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "    elif questions == \"04. Comments were made on each Video, and their corresponding Video Names\":\n",
    "        query4 = '''SELECT Comments as No_of_Comments, Title as VideoTitle FROM videos WHERE Comments IS NOT NULL'''\n",
    "        cursor.execute(query4)\n",
    "        t4 = cursor.fetchall()  # Fetch all results\n",
    "        conn.commit()\n",
    "\n",
    "        df4 = pd.DataFrame(t4, columns=[\"No_of_Comments\",\"VideoTitle\"])\n",
    "        st.write(df4)\n",
    "        \n",
    "    elif questions == \"05. Videos have the highest number of Likes, and their corresponding Channel Names\":\n",
    "        query5 = '''SELECT Title as VideoTitle, Channel_Name as ChannelName, Likes as No_of_Likes FROM videos\n",
    "                    WHERE Likes IS NOT NULL ORDER BY Likes DESC'''\n",
    "        cursor.execute(query5)\n",
    "        t5 = cursor.fetchall()  # Fetch all results\n",
    "        conn.commit()\n",
    "\n",
    "        df5 = pd.DataFrame(t5, columns=[\"VideoTitle\",\"ChannelName\",\"No_of_Likes\"])\n",
    "        st.write(df5)\n",
    "        \n",
    "    elif questions == \"06. The Total number of Likes for each Video, and their corresponding Video Names\":\n",
    "        query6 = '''SELECT Likes as LikeCounts, Title as VideoTitle FROM videos'''\n",
    "        cursor.execute(query6)\n",
    "        t6 = cursor.fetchall()  # Fetch all results\n",
    "        conn.commit()\n",
    "\n",
    "        df6 = pd.DataFrame(t6, columns=[\"LikeCount\",\"VideoTitle\"])\n",
    "        st.write(df6)\n",
    "        \n",
    "    elif questions == \"07. The Total number of Views for each Channel, and their corresponding Channel Names\":\n",
    "        query7 = '''SELECT Views as ViewCounts, Channel_Name as ChannelName FROM channels'''\n",
    "        cursor.execute(query7)\n",
    "        t7 = cursor.fetchall()  # Fetch all results\n",
    "        conn.commit()\n",
    "\n",
    "        df7 = pd.DataFrame(t7, columns=[\"ViewCount\",\"ChannelName\"])\n",
    "        st.write(df7)\n",
    "        st.write(\"### :green[Channels vs Views :]\")\n",
    "        # Create a Plotly Express bar chart\n",
    "        fig = px.bar(df7,\n",
    "                    x=\"ChannelName\",\n",
    "                    y=\"ViewCount\",\n",
    "                    orientation='v',\n",
    "                    color=\"ChannelName\"\n",
    "                    )\n",
    "\n",
    "        # Display the Plotly chart using Streamlit\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "    elif questions == \"08. The Names of All the Channels that have Published Videos in the Year 2022\":\n",
    "        query8 = '''SELECT Title as VideoTitle, Publish_At as VideoReleasDate, Channel_Name as ChannelName FROM videos\n",
    "                    WHERE EXTRACT(YEAR FROM Publish_At) = 2022'''\n",
    "        cursor.execute(query8)\n",
    "        t8 = cursor.fetchall()  # Fetch all results\n",
    "        conn.commit()\n",
    "\n",
    "        df8 = pd.DataFrame(t8, columns=[\"VideoTitle\",\"VideoReleaseDate\",\"ChannelName\"])\n",
    "        st.write(df8)\n",
    "        \n",
    "    elif questions == \"09. The Average Duration of All Videos in each Channel, and corresponding Channel Names\":\n",
    "        query9 = '''SELECT Channel_Name as ChannelName, TIME_FORMAT(SEC_TO_TIME(AVG(TIME_TO_SEC(TIME(Duration)))), '%H:%i:%s') as AverageDuration FROM videos GROUP BY Channel_Name'''\n",
    "        cursor.execute(query9)\n",
    "        t9 = cursor.fetchall()  # Fetch all results\n",
    "        conn.commit()\n",
    "\n",
    "        df9 = pd.DataFrame(t9, columns=[\"ChannelName\",\"AverageDuration\"])\n",
    "        \n",
    "        T9 = []\n",
    "        for index,row in df9.iterrows():\n",
    "            channel_title = row[\"ChannelName\"]\n",
    "            average_duration = row[\"AverageDuration\"]\n",
    "            average_duration_str = str(average_duration)\n",
    "            T9.append(dict(ChannelTitle = channel_title,AvgDuration = average_duration_str))\n",
    "        df11 = pd.DataFrame(T9)\n",
    "        st.write(df11)\n",
    "        st.write(\"### :green[Avg video duration for channels :]\")\n",
    "            # Create a Plotly Express bar chart\n",
    "        fig = px.bar(df9,\n",
    "                    x=\"ChannelName\",\n",
    "                    y=\"AverageDuration\",\n",
    "                    orientation='v',\n",
    "                    color=\"ChannelName\"\n",
    "                    )\n",
    "\n",
    "        # Display the Plotly chart using Streamlit\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    elif questions == \"10. Videos have the highest number of Comments, and their corresponding Channel Names\":\n",
    "        query10 = '''SELECT Title as VideoTitle, Channel_Name as ChannelName, Comments as comments FROM videos\n",
    "                    WHERE Comments IS NOT NULL ORDER BY Comments DESC'''\n",
    "        cursor.execute(query10)\n",
    "        t10 = cursor.fetchall()  # Fetch all results\n",
    "        conn.commit()\n",
    "\n",
    "        df10 = pd.DataFrame(t10, columns=[\"videoTitle\",\"ChannelName\",\"comments\"])\n",
    "        st.write(df10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing MySQL table in streamlit\n",
    "# Database connection parameters\n",
    "config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': 'up78aq3670',\n",
    "    'database': 'youtube_data'\n",
    "}\n",
    "# Streamlit app\n",
    "st.header(':green[MySQL Data Viewer]')\n",
    "\n",
    "Mysql_table = st.checkbox('**Check MySQL Table**')\n",
    "\n",
    "if Mysql_table:\n",
    "    # Function to fetch data from the selected table\n",
    "    def fetch_data(selected_table):\n",
    "        conn = mysql.connector.connect(**config)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        query = f\"SELECT * FROM {selected_table};\"\n",
    "        cursor.execute(query)\n",
    "\n",
    "        data = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "        return df\n",
    "    \n",
    "    # Radio button to select the table\n",
    "    selected_table = st.radio(\"Select a table\", [\"channels\", \"playlists\", \"comments\", \"videos\",])\n",
    "\n",
    "    # Fetch data based on the selected table\n",
    "    df = fetch_data(selected_table)\n",
    "\n",
    "    # Show the entire DataFrame using st.table\n",
    "    st.table(df)\n",
    "\n",
    "    # If there's a troublesome column, display it separately\n",
    "    troublesome_column_name = 'troublesome_column'\n",
    "    if troublesome_column_name in df.columns:\n",
    "        st.write(f\"Troublesome Column ({troublesome_column_name}):\")\n",
    "        st.table(df[troublesome_column_name])\n",
    "\n",
    "cursor.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
